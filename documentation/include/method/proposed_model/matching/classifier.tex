% !TEX root = ..\..\..\..\main.tex
\subsubsection{Classifier}
\label{sec:method:proposed:matching:classifier}
As mentioned in Section \ref{sec:intro:delimitations}, there was no plan to compare how well different classifiers would perform in this thesis. 
But since having many dimensions can result in more general predictions, a classifier that scales well is to prefer. A classifier that is capable of handling a high number of dimensions is the support vector machine (SVM), see Section \ref{sec:mltheory:svm}. 
Comparative studies such as \cite{IRJET2017classificationMethods}, \cite{SMMR2016comparisionClassificationMethods} and \cite{Informatica2007revClassification} have deemed SVMs as classifiers that continuously show good results in different implementations. 

In the field of CBIR there are myriads of different feature descriptors that are used and the more feature descriptors one can combine, the more general the classifier can become. As mentioned in Section \ref{sec:intro:delimitations} the number of different feature descriptors used in this thesis is limited to five. This solely because adding or removing feature descriptors could improve performance in a general sense, but there was not enough time to cover the subject. In order to combine these five feature descriptors a tree of SVMs were created; one for every feature descriptor and one that treats the output of the different SVMs as input. Read more about the classifier structure \emph{Deep SVM} in Section \ref{sec:deepSVM}. 

As mentioned in Section \ref{sec:method:rel_approaches}, most CBIR systems can quantify certainty of relevance by using a distance function in order to sort the material from most to least relevant. SVMs are geometrical tools that create a decision boundary in some dimensional space to split the categories so they can be categorized depending on which side they are of the decision boundary. Due to the fact that the relevance feedback module expects the material to be sorted the certainty of the classification needs to be quantified. Instead of using the \emph{sign} function to determine the category of an image, the matching module can use the distance between each data point and the decision boundary, a quantification method that is mentioned in Section \ref{sec:mltheory:svm}, to see how probable it is that some image belongs to a certain category. This gives the matching module the possibility to sort the data from the most to the least relevant and the categories of the data points can still be predicted by using the sign function later on.


