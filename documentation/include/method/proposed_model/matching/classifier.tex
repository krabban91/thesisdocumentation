% !TEX root = ..\..\..\..\main.tex
\subsubsection{Classifier}
\label{sec:method:proposed:matching:classifier}
As mentioned in Section \ref{sec:intro:delimitations}, there was no plan to compare how well different classifiers would perform in this thesis. 
But since having many dimensions can result in more general decisions, a classifier that scales well is to prefer. \todo{A}One classifier that is capable of handling a high number of dimensions is the support vector machine (\todo{remove an}an SVM), see Section \ref{sec:mltheory:svm}. 
Comparative studies such as \cite{IRJET2017classificationMethods}, \cite{SMMR2016comparisionClassificationMethods} and \cite{Informatica2007revClassification} have deemed SVMs as classifiers that continuously show good results in different implementations. 

In the field of CBIR there are myriads of different feature descriptors that are used and the more feature descriptors one can combine, the more general the classifier can become. As mentioned in Section \ref{sec:intro:delimitations} the number of different feature descriptors used in this thesis is limited to 5\todo{five}. This solely because adding or removing feature descriptors could improve performance in a general sense, but there was not enough time to cover the subject. In order to combine these 5\todo{five} feature descriptors a tree of SVMs were created; one for every feature descriptor and one that treats the output of the different SVMs as input. Read more about the classifier structure \emph{Deep SVM} in Section \ref{sec:deepSVM}. 

As mentioned in Section \ref{sec:method:rel_approaches}, most CBIR systems can quantify certainty of relevance by using a distance function in order to sort the material from most to least relevant. SVMs are geometrical tools that create a decision boundary in some dimensional space in order to say that all points on one side is one category and all points on the other side is another. Due to the fact that the relevance feedback module expects the material to be sorted the certainty of the classification needs to be quantified. A quantification method is mentioned in Section \ref{sec:mltheory:svm}: Instead of using the \emph{sign} function to decide a class, just use the distance that each data point has from the decision boundary. This gives the matching module the possibility to sort the data from the most to the least relevant and the category\todo{categories of the data points can still be predicted by using the sign function later on.} of the point can still be categorized by using the sign function later on. 


