% !TEX root = ..\..\..\main.tex

\subsection{Relevance feedback module}
\label{sec:method:proposed:rf}
There are numerous ways of using relevance feedback in order to improve CBIR and to categorize material. In Section \ref{sec:theory:relfeed} the different ways of relevance feedback are divided into three categories and they are referred to as explicit, implicit and blind feedback. 
In order to make elaborate guesses the model needs to have validated data in its training set and as mentioned in Chapter \ref{chapter:intro} all the case material has to be handled by an investigator in order to build a case. The model has therefore been designed to use explicit feedback in the end of each search iteration.

The feedback that the model receives from the user gives the module information about which images that were correctly categorized and which images that were falsely categorized as negatives and positives. \todo{does the sentence need to be elaborated?}This information could be used to prevent similar mistakes to happen when categorizing the same images. This will however not happen because these images can from this point be used in the training set instead of found in the unlabeled search space and will thereby not be falsely categorized again. Due to the fact that the model is designed to deplete the search space of relevant images, the only information that is drawn from relevance feedback in this model is the knowledge of which images that are relevant and which are not\todo{and which are not, omitt? The one comes with the other} for the specific case. This knowledge is passed on to the feature extraction module and the search iteration is then terminated as seen in Figure \ref{fig:meth:proposed:rf_module}.

\singlefigurenear
{figure/relevance_feedback_module.PNG}
{The relevance feedback module is the intermediator of the user and the rest of the model. When the feedback is given by the user the search iteration can be terminated.}
{fig:meth:proposed:rf_module}
{0.5}

The information that the relevance feedback module receives from the matching module is overly simplified to reduce calculations. The material that is received is sorted to have the most relevant images first and the least relevant images last. The material is however only labeled as relevant and non-relevant. But to present all the material at once would be overwhelming for the user and the model would not need to learn iteratively. 
To present the \emph{top-k} images is a common method within CBIR, and the number of images that are presented could make it easier for the user to oversee the material. The number 20 was arbitrarily chosen and was empirically manageable. An extension to this \emph{top-20} approach in order to improve classification was to also to present some images from the other extreme; the \emph{bottom-k} images. With the intent to avoid drowning the user with information it sufficed with 5 images. Resulting in that the user could quickly give feedback to 25 images in total every iteration\todo{we mention later that we had a trial and error for different setups, is this in line with this text?}. 
